# FimAI Chat

A modern, feature-rich AI chat application built with Next.js, supporting multiple AI providers and comprehensive user management.

## âœ¨ Features

### ğŸ¤– Multi-Provider AI Support
- Support for multiple AI service providers (OpenAI, Claude, etc.)
- Custom model management with drag-and-drop reordering
- Model grouping and organization
- Real-time model availability checking via `/v1/models` API
- Automatic model icon matching and colorful UI

### ğŸ’¬ Advanced Chat Interface
- Real-time streaming chat responses
- Markdown rendering with LaTeX formula support
- Message action buttons (copy, delete, edit)
- Chat history with AI-generated titles
- Per-message model recording
- Token usage tracking and display
- Clean, modern UI with consistent spacing

### ğŸ‘¥ Three-Tier User Management
- **Admin**: Full control panel access with hardcoded invite codes
- **User**: Invite code registration with token tracking and access code sharing
- **Guest**: Access code login with local storage and token counting

### ğŸ”§ Configuration Management
- Intuitive config page for API settings
- Provider management with add/delete functionality
- Model configuration with custom parameters
- Collapsible sections with drag handles for reordering
- Batch AI renaming with smart formatting rules

### ğŸ—„ï¸ Database Integration
- SQLite database with Prisma ORM
- Conversation and message persistence
- User permissions and token usage tracking
- Migration from localStorage to database storage

### ğŸ¨ UI/UX Features
- Black and white design aesthetic
- HTML5-style toast notifications
- Enhanced checkbox UI for model enable/disable
- Hierarchical dropdown model selection
- Responsive design for web and mobile

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- npm, yarn, or pnpm

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd fim-ai-chat
```

2. Install dependencies:
```bash
npm install
# or
yarn install
# or
pnpm install
```

3. Set up the database:
```bash
npm run db:generate
npm run db:migrate
```

4. Start the development server:
```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ app/                    # Next.js app router pages
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”œâ”€â”€ chat/              # Chat interface
â”‚   â”œâ”€â”€ config/            # Configuration page
â”‚   â””â”€â”€ login/             # Authentication
â”œâ”€â”€ components/            # Reusable UI components
â”œâ”€â”€ lib/                   # Utility functions and database
â”œâ”€â”€ types/                 # TypeScript type definitions
â””â”€â”€ styles/               # Global styles

prisma/
â”œâ”€â”€ schema.prisma         # Database schema
â””â”€â”€ seed.ts              # Database seeding
```

## ğŸ› ï¸ Available Scripts

- `npm run dev` - Start development server with Turbopack
- `npm run build` - Build for production
- `npm run start` - Start production server
- `npm run lint` - Run ESLint
- `npm run db:generate` - Generate Prisma client
- `npm run db:migrate` - Run database migrations
- `npm run db:seed` - Seed database with initial data
- `npm run db:studio` - Open Prisma Studio
- `npm run db:reset` - Reset database

## ğŸ”§ Configuration

### Environment Variables

Create a `.env.local` file in the root directory:

```env
DATABASE_URL="file:./dev.db"
NEXTAUTH_SECRET="your-secret-key"
```

### AI Provider Setup

1. Navigate to `/config` page
2. Add your AI providers with API keys
3. Configure available models
4. Set up user permissions and token limits

## ğŸ—ï¸ Tech Stack

- **Framework**: Next.js 15 with App Router
- **Database**: SQLite with Prisma ORM
- **Styling**: Tailwind CSS
- **UI Components**: Custom components with @lobehub/ui
- **Icons**: @lobehub/icons-static-svg
- **Markdown**: react-markdown with LaTeX support
- **Drag & Drop**: @dnd-kit
- **Authentication**: Custom user management system

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Support

If you encounter any issues or have questions, please open an issue on GitHub.
